{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"index in progress","text":""},{"location":"aiconcepts/","title":"AI Concepts","text":"<p>This section describes core concepts that Spring AI uses. We recommend reading it closely to understand the ideas behind how Spring AI is implemented.</p>"},{"location":"aiconcepts/#models","title":"Models","text":"<p>AI models are algorithms crafted to process and generate information, often emulating human cognitive functions. By discovering patterns and insights within large datasets, these models can produce predictions, text, images, or other outputs, thereby enhancing various industry applications.</p> <p>AI models come in various types, each tailored for specific use cases. While ChatGPT has gained attention for its generative AI capabilities in text input and output, numerous models and companies offer a variety of inputs and outputs. Prior to ChatGPT, text-to-image generation models like Midjourney and Stable Diffusion intrigued many users.</p> <p>The table below categorizes several models based on their input and output types:</p> <p></p> <p>Spring AI currently supports models that process input and output as language, image, and audio. The last row in the previous table, which accepts text as input and outputs numbers, is more commonly known as embedding text and represents the internal data structures used in an AI model. Spring AI has support for embeddings to support more advanced use cases.</p> <p>What sets models like GPT apart is their pre-trained nature, as indicated by the \"P\" in GPT\u2014Chat Generative Pre-trained Transformer. This pre-training feature transforms AI into a general developer tool that does not require an extensive machine learning or model training background.</p>"},{"location":"aiconcepts/#prompts","title":"Prompts","text":"<p>Prompts are the key instructions we give to an AI model to get specific responses. If you've used ChatGPT, you might think a prompt is just the text you type in. However, it's more than that. In many AI models, a prompt includes various parts, not just a simple sentence.</p> <p>ChatGPT\u2019s API uses different types of text inputs within a prompt, each with a specific role. For instance, there's a \"system\" role that guides the model on how to behave and sets the scene for the interaction. There's also a \"user\" role, which is the input from you, the user.</p> <p>Creating good prompts is both an art and a science. ChatGPT is designed to engage in human-like conversations. This is very different from using something like SQL to \"ask a question.\" With AI, you have to communicate like you're talking to another person.</p> <p>The importance of this interaction has led to the field of \"Prompt Engineering.\" This involves various techniques to improve how prompts are crafted. Spending time on crafting a good prompt can greatly enhance the AI\u2019s response.</p> <p>People now often share prompts, and there's a lot of academic research on this topic. For example, crafting an effective prompt can be quite surprising. A recent study found that a very effective prompt starts with, \u201cTake a deep breath and work on this step by step.\u201d This shows how crucial language is. We are still learning how to best use previous AI models like ChatGPT 3.5, and even newer versions are being developed.</p>"},{"location":"aiconcepts/#prompt-templates","title":"Prompt Templates","text":"<p>Creating effective prompts involves establishing the context of the request and substituting parts of the request with values specific to the user\u2019s input. This process uses traditional text-based template engines for prompt creation and management. Spring AI employs the OSS library StringTemplate for this purpose. For instance, consider the simple prompt template: <pre><code>Tell me a {adjective} joke about {content}.\n</code></pre></p> <p>In Spring AI, prompt templates can be likened to the \"'View'\" in Spring MVC architecture. A model object, typically a java.util.Map, is provided to populate placeholders within the template. The \"'rendered'\" string becomes the content of the prompt supplied to the AI model.</p> <p>There is considerable variability in the specific data format of the prompt sent to the model. Initially starting as simple strings, prompts have evolved to include multiple messages, where each string in each message represents a distinct role for the model.</p>"},{"location":"aiconcepts/#embeddings","title":"Embeddings","text":"<p>Embeddings transform text into numerical arrays or vectors, enabling AI models to process and interpret language data. This transformation from text to numbers is a key element in how AI interacts with and understands human language.</p> <p></p> <p>As a Java developer exploring AI, it\u2019s not necessary to comprehend the intricate mathematical theories or the specific implementations behind these vector representations. A basic understanding of their role and function within AI systems suffices, particularly when you\u2019re integrating AI functionalities into your applications.</p> <p>Embeddings are particularly relevant in practical applications like the Retrieval Augmented Generation (RAG) pattern. They enable the representation of data as points in a semantic space, which is akin to the 2-D space of Euclidean geometry, but in higher dimensions. This means just like how points on a plane in Euclidean geometry can be close or far based on their coordinates, in a semantic space, the proximity of points reflects the similarity in meaning. Sentences about similar topics are positioned closer in this multi-dimensional space, much like points lying close to each other on a graph. This proximity aids in tasks like text classification, semantic search, and even product recommendations, as it allows the AI to discern and group related concepts based on their 'location' in this expanded semantic landscape.</p> <p>You can think of this semantic space as a vector.</p>"},{"location":"aiconcepts/#tokens","title":"Tokens","text":"<p>Tokens serve as the building blocks of how an AI model works. On input, models convert words to tokens. On output, they convert tokens back to words.</p> <p>In English, one token roughly corresponds to 75% of a word. For reference, Shakespeare\u2019s complete works, totaling around 900,000 words, translates to approximately 1.2 million tokens.</p> <p></p> <p>Perhaps more important is that Tokens = Money. In the context of hosted AI models, your charges are determined by the number of tokens used. Both input and output contribute to the overall token count.</p> <p>Also, models are subject to token limits, which restrict the amount of text processed in a single API call. This threshold is often referred to as the 'context window'. The model does not process any text that exceeds this limit.</p> <p>For instance, ChatGPT3 has a 4K token limit, while GPT4 offers varying options, such as 8K, 16K, and 32K. Anthropic\u2019s Claude AI model features a 100K token limit, and Meta\u2019s recent research yielded a 1M token limit model.</p> <p>To summarize the collected works of Shakespeare with GPT4, you need to devise software engineering strategies to chop up the data and present the data within the model\u2019s context window limits. The Spring AI project helps you with this task.</p>"},{"location":"aiconcepts/#bringing-your-data-apis-to-the-ai-model","title":"Bringing Your Data &amp; APIs to the AI Model","text":"<p>How can you equip the AI model with information on which it has not been trained?</p> <p>Note that the GPT 3.5/4.0 dataset extends only until September 2021. Consequently, the model says that it does not know the answer to questions that require knowledge beyond that date. An interesting bit of trivia is that this dataset is around 650GB.</p> <p>Three techniques exist for customizing the AI model to incorporate your data:</p> <ul> <li> <p>Fine Tuning: This traditional machine learning technique involves tailoring the model and changing its internal weighting. However, it is a challenging process for machine learning experts and extremely resource-intensive for models like GPT due to their size. Additionally, some models might not offer this option.</p> </li> <li> <p>Prompt Stuffing: A more practical alternative involves embedding your data within the prompt provided to the model. Given a model\u2019s token limits, techniques are required to present relevant data within the model\u2019s context window. This approach is colloquially referred to as \u201cstuffing the prompt.\u201d The Spring AI library helps you implement solutions based on the \u201cstuffing the prompt\u201d technique otherwise known as Retrieval Augmented Generation (RAG).</p> </li> </ul> <p></p>"},{"location":"aiconcepts/#retrieval-augmented-generation","title":"Retrieval Augmented Generation","text":"<p>A technique termed Retrieval Augmented Generation (RAG) has emerged to address the challenge of incorporating relevant data into prompts for accurate AI model responses.</p> <p>The approach involves a batch processing style programming model, where the job reads unstructured data from your documents, transforms it, and then writes it into a vector database. At a high level, this is an ETL (Extract, Transform and Load) pipeline. The vector database is used in the retrieval part of RAG technique.</p> <p>As part of loading the unstructured data into the vector database, one of the most important transformations is to split the original document into smaller pieces. The procedure of splitting the original document into smaller pieces has two important steps:</p> <p>Split the document into parts while preserving the semantic boundaries of the content. For example, for a document with paragraphs and tables, one should avoid splitting the document in the middle of a paragraph or table. For code, avoid splitting the code in the middle of a method\u2019s implementation.</p> <p>Split the document\u2019s parts further into parts whose size is a small percentage of the AI Model\u2019s token limit.</p> <p>The next phase in RAG is processing user input. When a user\u2019s question is to be answered by an AI model, the question and all the \u201csimilar\u201d document pieces are placed into the prompt that is sent to the AI model. This is the reason to use a vector database. It is very good at finding similar content.</p> <p></p> <ul> <li> <p>The ETL pipeline provides further information about orchestrating the flow of extracting data from the data sources and store it in a structured vector store, ensuring data is in the optimal format for retrieval by the AI model.</p> </li> <li> <p>The ChatClient - RAG explains how to use the QuestionAnswerAdvisor advisor to enable the RAG capability to your application.</p> </li> </ul>"},{"location":"getstarted/","title":"Get Started","text":"<p>Spring reference link for Get started</p> <p>Spring Azure OpenAI Example Repo </p> <p>Spring Aws AI Example Repo </p> <p>Spring VectorDb AI Example Repo </p>"},{"location":"overview/","title":"Spring AI","text":"<p>The Spring AI project aims to streamline the development of applications that incorporate artificial intelligence functionality without unnecessary complexity.</p> <p>The project draws inspiration from notable Python projects, such as LangChain and LlamaIndex, but Spring AI is not a direct port of those projects. The project was founded with the belief that the next wave of Generative AI applications will not be only for Python developers but will be ubiquitous across many programming languages.</p> <p>At its core, Spring AI provides abstractions that serve as the foundation for developing AI applications. These abstractions have multiple implementations, enabling easy component swapping with minimal code changes.</p> <p>Spring AI provides the following features:</p> <ul> <li>Support for all major Model providers such as OpenAI, Microsoft, Amazon, Google, and Hugging Face.</li> <li>Supported Model types are Chat, Text to Image, Audio Transcription, Text to Speech, and more on the way.</li> <li>Portable API across AI providers for all models. Both synchronous and stream API options are supported. Dropping down to access model specific features is also    supported.</li> <li>Mapping of AI Model output to POJOs.</li> <li>Support for all major Vector Database providers such as Apache Cassandra, Azure Vector Search, Chroma, Milvus, MongoDB Atlas, Neo4j, Oracle, PostgreSQL/PGVector,    PineCone, Qdrant, Redis, and Weaviate.</li> <li>Portable API across Vector Store providers, including a novel SQL-like metadata filter API that is also portable.</li> <li>Function calling.</li> <li>Spring Boot Auto Configuration and Starters for AI Models and Vector Stores.</li> <li>ETL framework for Data Engineering.</li> </ul> <p>This feature set lets you implement common use cases such as \u201cQ&amp;A over your documentation\u201d or \u201cChat with your documentation.\u201d</p> <p>The concepts section provides a high-level overview of AI concepts and their representation in Spring AI.</p> <p>The Getting Started section shows you how to create your first AI application. Subsequent sections delve into each component and common use cases with a code-focused approach.</p>"},{"location":"ai/chat-client/","title":"Chat Client API","text":"<p>The ChatClient offers a fluent API for communicating with an AI Model. It supports both synchronous and reactive programming models.</p>"},{"location":"ai/chat-client/#key-features","title":"Key Features:","text":"<ol> <li>Fluent API Methods:</li> <li>The API provides methods to build the different parts of a prompt, which is then sent to the AI model as input.</li> <li> <p>A prompt includes instructional text to guide the AI model\u2019s output and behavior.</p> </li> <li> <p>Prompt Structure:</p> </li> <li>Prompts consist of a collection of messages.</li> <li>User Messages: Direct inputs from the user.</li> <li> <p>System Messages: Generated by the system to guide the conversation.</p> </li> <li> <p>Dynamic Message Content:</p> </li> <li> <p>Messages often contain placeholders that are substituted at runtime based on user input. This customization tailors the AI model\u2019s response to the user's input.</p> </li> <li> <p>Prompt Options:</p> </li> <li>Various options can be specified for a prompt, such as:<ul> <li>AI Model Name: The specific AI model to use.</li> <li>Temperature Setting: Controls the randomness or creativity of the generated output.</li> </ul> </li> </ol>"},{"location":"ai/chat-client/#creating-a-chatclient","title":"Creating a ChatClient","text":"<p>The ChatClient is created using a ChatClient.Builder object. You can obtain an autoconfigured ChatClient.Builder instance for any ChatModel Spring Boot autoconfiguration or create one programmatically.</p>"},{"location":"ai/chat-client/#using-an-autoconfigured-chatclientbuilder","title":"Using an autoconfigured ChatClient.Builder","text":"<p>In the most simple use case, Spring AI provides Spring Boot autoconfiguration, creating a prototype ChatClient.Builder bean for you to inject into your class. Here is a simple example of retrieving a String response to a simple user request.</p> <pre><code>@RestController\npublic class AzureChatController {\n\n    private final AzureOpenAiChatModel chatModel;\n\n    public AzureChatController(AzureOpenAiChatModel chatModel) {\n        this.chatModel = chatClientBuilder.build();\n    }\n\n    @GetMapping(\"azure/ai/multimodality\")\n      public String generateMultimodality(@RequestParam(value = \"message\", defaultValue = \"Explain what do you see on this picture?\") String question, @RequestParam(value = \"modelName\", defaultValue = \"gpt-4-turbo-2024-04-09\") String modelName,\n            @RequestParam(value = \"imageURL\", defaultValue = \"https://docs.spring.io/spring-ai/reference/_images/multimodal.test.png\") String imageURL) throws MalformedURLException {\n        URL url = new URL(imageURL);\n        String response = ChatClient.create(chatModel).prompt()\n                .options(AzureOpenAiChatOptions.builder().withDeploymentName(modelName).build())\n                .user(u -&gt; u.text(question).media(MimeTypeUtils.IMAGE_PNG, url))\n                .call()\n                .content();\n        return response;\n    }\n</code></pre> <p>In this simple example, the user input sets the contents of the user message. The call method sends a request to the AI model, and the content method returns the AI model\u2019s response as a String.</p>"},{"location":"ai/chat-client/#create-a-chatclient-programmatically","title":"Create a ChatClient programmatically","text":"<p>You can disable the ChatClient.Builder autoconfiguration by setting the property spring.ai.chat.client.enabled=false. This is useful if multiple chat models are used together. Then create a ChatClient.Builder instance for for every ChatModel programmatically: <pre><code>ChatModel myChatModel = ... // usually autowired\n\nChatClient.Builder builder = ChatClient.builder(myChatModel);\n\n// or create a ChatClient with the default builder settings:\n\nChatClient chatClient = ChatClient.create(myChatModel);\n</code></pre></p>"},{"location":"ai/chat-client/#chatclient-responses","title":"ChatClient Responses","text":"<p>The ChatClient API offers several ways to format the response from the AI Model.</p>"},{"location":"ai/chat-client/#returning-a-chatresponse","title":"Returning a ChatResponse","text":"<p>In progress ...</p>"},{"location":"ai/chat-client/#streaming-responses","title":"Streaming Responses","text":"<p>In progress ...</p>"},{"location":"ai/chat-client/#call-return-values","title":"call() return values","text":"<p>In progress ...</p>"},{"location":"ai/chat-client/#stream-return-values","title":"stream() return values","text":"<p>In progress ...</p>"},{"location":"ai/chat-model/","title":"Chat Model API","text":"<p>The Chat Model API offers developers the ability to integrate AI-powered chat completion capabilities into their applications. It leverages pre-trained language models, such as GPT (Generative Pre-trained Transformer), to generate human-like responses to user inputs in natural language.</p> <p>The API typically works by sending a prompt or partial conversation to the AI model, which then generates a completion or continuation of the conversation based on its training data and understanding of natural language patterns. The completed response is then returned to the application, which can present it to the user or use it for further processing.</p> <p>The Spring AI Chat Model API is designed to be a simple and portable interface for interacting with various AI Models, allowing developers to switch between different models with minimal code changes. This design aligns with Spring\u2019s philosophy of modularity and interchangeability.</p> <p>Also with the help of companion classes like Prompt for input encapsulation and ChatResponse for output handling, the Chat Model API unifies the communication with AI Models. It manages the complexity of request preparation and response parsing, offering a direct and simplified API interaction.</p>"},{"location":"ai/chat-model/#api-overview","title":"API Overview","text":"<p>This section provides a guide to the Spring AI Chat Model API interface and associated classes.</p>"},{"location":"ai/chat-model/#chatmodel","title":"ChatModel","text":"<p>Here is the ChatModel interface definition:</p> <pre><code>public interface ChatModel extends Model&lt;Prompt, ChatResponse&gt; {\n\n    default String call(String message) {// implementation omitted\n    }\n\n    @Override\n    ChatResponse call(Prompt prompt);\n}\n</code></pre> <p>The call method with a String parameter simplifies initial use, avoiding the complexities of the more sophisticated Prompt and ChatResponse classes. In real-world applications, it is more common to use the call method that takes a Prompt instance and returns an ChatResponse.</p>"},{"location":"ai/chat-model/#streamingchatmodel","title":"StreamingChatModel","text":"<p>Here is the StreamingChatModel interface definition:</p> <p><pre><code>public interface StreamingChatModel extends StreamingModel&lt;Prompt, ChatResponse&gt; {\n    @Override\n    Flux&lt;ChatResponse&gt; stream(Prompt prompt);\n}\n</code></pre> The stream method takes a Prompt request similar to ChatModel but it streams the responses using the reactive Flux API. </p>"},{"location":"ai/chat-model/#prompt","title":"Prompt","text":"<p>The Prompt is a ModelRequest that encapsulates a list of Message objects and optional model request options. The following listing shows a truncated version of the Prompt class, excluding constructors and other utility methods:</p> <pre><code>public class Prompt implements ModelRequest&lt;List&lt;Message&gt;&gt; {\n\n    private final List&lt;Message&gt; messages;\n\n    private ChatOptions modelOptions;\n\n    @Override\n    public ChatOptions getOptions() {..}\n\n    @Override\n    public List&lt;Message&gt; getInstructions() {...}\n\n    // constructors and utility methods omitted\n}\n</code></pre>"},{"location":"ai/chat-model/#message","title":"Message","text":"<p>The Message interface encapsulates a textual message, a collection of attributes as a Map, and a categorization known as MessageType. The interface is defined as follows:</p> <p><pre><code>public interface Message extends Node&lt;String&gt; {\n\n   String getContent();\n\n   List&lt;Media&gt; getMedia();\n\n   MessageType getMessageType();\n}\n</code></pre> and the Node interface is</p> <pre><code>public interface Node&lt;T&gt; {\n\n    T getContent();\n\n    Map&lt;String, Object&gt; getMetadata();\n}\n</code></pre> <p>The Message interface has various implementations that correspond to the categories of messages that an AI model can process. Some models, like OpenAI\u2019s chat completion endpoint, distinguish between message categories based on conversational roles, effectively mapped by the MessageType.</p> <p>For instance, OpenAI recognizes message categories for distinct conversational roles such as system,user, function or assistant.</p> <p>While the term MessageType might imply a specific message format, in this context it effectively designates the role a message plays in the dialogue.</p> <p>For AI models that do not use specific roles, the UserMessage implementation acts as a standard category, typically representing user-generated inquiries or instructions. To understand the practical application and the relationship between Prompt and Message, especially in the context of these roles or message categories, see the detailed explanations in the Prompts section.</p>"},{"location":"ai/chat-model/#chat-options","title":"Chat Options","text":"<p>Represents the options that can be passed to the AI model. The ChatOptions class is a subclass of ModelOptions and is used to define few portable options that can be passed to the AI model. The ChatOptions class is defined as follows:</p> <pre><code>public interface ChatOptions extends ModelOptions {\n\n    Float getTemperature();\n    void setTemperature(Float temperature);\n    Float getTopP();\n    void setTopP(Float topP);\n    Integer getTopK();\n    void setTopK(Integer topK);\n}\n</code></pre> <p>Additionally, every model specific ChatModel/StreamingChatModel implementation can have its own options that can be passed to the AI model. For example, the OpenAI Chat Completion model has its own options like presencePenalty, frequencyPenalty, bestOf etc.</p> <p>This is a powerful feature that allows developers to use model specific options when starting the application and then override them with at runtime using the Prompt request:</p> <p></p>"},{"location":"ai/chat-model/#chatresponse","title":"ChatResponse","text":"<p>The structure of the ChatResponse class is as follows: <pre><code>public class ChatResponse implements ModelResponse&lt;Generation&gt; {\n\n    private final ChatResponseMetadata chatResponseMetadata;\n    private final List&lt;Generation&gt; generations;\n\n    @Override\n    public ChatResponseMetadata getMetadata() {...}\n\n    @Override\n    public List&lt;Generation&gt; getResults() {...}\n\n    // other methods omitted\n}\n</code></pre> The ChatResponse class holds the AI Model\u2019s output, with each Generation instance containing one of potentially multiple outputs resulting from a single prompt.</p> <p>The ChatResponse class also carries a ChatResponseMetadata metadata about the AI Model\u2019s response.</p>"},{"location":"ai/chat-model/#generation","title":"Generation","text":"<p>Finally, the Generation class extends from the ModelResult to represent the output assistant message response and related metadata about this result:</p> <pre><code>public class Generation implements ModelResult&lt;AssistantMessage&gt; {\n\n    private AssistantMessage assistantMessage;\n    private ChatGenerationMetadata chatGenerationMetadata;\n\n    @Override\n    public AssistantMessage getOutput() {...}\n\n    @Override\n    public ChatGenerationMetadata getMetadata() {...}\n\n    // other methods omitted\n}\n</code></pre>"},{"location":"ai/chat-model/#available-implementations","title":"Available Implementations","text":"<p>The ChatModel and StreamingChatModel implementations are provided for the following Model providers:</p> <p></p>"},{"location":"ai/chat-model/#chat-model-api_1","title":"Chat Model API","text":"<p>The Spring AI Chat Model API is build on top of the Spring AI Generic Model API providing Chat specific abstractions and implementations. Following class diagram illustrates the main classes and interfaces of the Spring AI Chat Model API.</p> <p></p>"},{"location":"ai/embedd-model/","title":"Overview","text":"<p>in progress</p>"},{"location":"ai/vectordb/","title":"Overview","text":"<p>in progress</p>"},{"location":"tags/","title":"Tags","text":"<p>This page shows a list of pages indexed by their tags:</p>"}]}